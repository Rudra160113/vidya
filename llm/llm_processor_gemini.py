# File location: vidya/llm/llm_processor_gemini.py

import logging
import google.generativeai as genai
from vidya.config.configuration_manager import ConfigurationManager
from vidya.security.api_key_manager import APIKeyManager

class LLMProcessorGemini:
    """
    Processes user input using the Google Gemini API to generate a response.
    """
    def __init__(self, config_manager: ConfigurationManager, api_key_manager: APIKeyManager):
        self.config_manager = config_manager
        self.api_key_manager = api_key_manager
        self._setup_api_client()
        logging.info("LLMProcessorGemini initialized.")

    def _setup_api_client(self):
        """Configures the Gemini API client with the API key."""
        gemini_key = self.api_key_manager.get_key('gemini')
        if gemini_key:
            genai.configure(api_key=gemini_key)
            self.model = genai.GenerativeModel('gemini-pro')
            logging.info("Gemini API key loaded and client configured.")
        else:
            logging.error("Gemini API key not found. LLM functionality will be disabled.")
            self.model = None

    def generate_response(self, prompt: str, history: list = None) -> str:
        """
        Generates a text response from the Gemini model.

        Args:
            prompt (str): The user's input or command.
            history (list): A list of previous messages for context.

        Returns:
            str: The generated response from the LLM.
        """
        if not self.model:
            return "I am unable to process your request. My API key is not configured."

        try:
            # The API allows for a chat history to be passed
            chat_session = self.model.start_chat(history=history or [])
            response = chat_session.send_message(prompt)
            logging.info("Response generated by Gemini API.")
            return response.text
        except Exception as e:
            logging.error(f"Error generating response from Gemini API: {e}")
            return "I'm sorry, I encountered an error. Please try again."
